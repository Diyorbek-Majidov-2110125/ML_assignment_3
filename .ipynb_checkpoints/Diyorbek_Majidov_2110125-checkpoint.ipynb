{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types in the Training Data:\n",
      "F0       int64\n",
      "F1       int64\n",
      "F2       int64\n",
      "F3       int64\n",
      "F4       int64\n",
      "F5       int64\n",
      "F6       int64\n",
      "F7       int64\n",
      "F8       int64\n",
      "F9       int64\n",
      "F10      int64\n",
      "F11      int64\n",
      "F12      int64\n",
      "F13      int64\n",
      "F14      int64\n",
      "F15      int64\n",
      "F16      int64\n",
      "F17      int64\n",
      "F18      int64\n",
      "F19      int64\n",
      "F20      int64\n",
      "F21      int64\n",
      "F22      int64\n",
      "F23      int64\n",
      "F24      int64\n",
      "F25      int64\n",
      "F26      int64\n",
      "F27      int64\n",
      "F28      int64\n",
      "F29      int64\n",
      "F30      int64\n",
      "F31      int64\n",
      "F32      int64\n",
      "F33      int64\n",
      "F34      int64\n",
      "F35      int64\n",
      "Class    int64\n",
      "dtype: object\n",
      "\n",
      "Data Types in the Test Data:\n",
      "F0       int64\n",
      "F1       int64\n",
      "F2       int64\n",
      "F3       int64\n",
      "F4       int64\n",
      "F5       int64\n",
      "F6       int64\n",
      "F7       int64\n",
      "F8       int64\n",
      "F9       int64\n",
      "F10      int64\n",
      "F11      int64\n",
      "F12      int64\n",
      "F13      int64\n",
      "F14      int64\n",
      "F15      int64\n",
      "F16      int64\n",
      "F17      int64\n",
      "F18      int64\n",
      "F19      int64\n",
      "F20      int64\n",
      "F21      int64\n",
      "F22      int64\n",
      "F23      int64\n",
      "F24      int64\n",
      "F25      int64\n",
      "F26      int64\n",
      "F27      int64\n",
      "F28      int64\n",
      "F29      int64\n",
      "F30      int64\n",
      "F31      int64\n",
      "F32      int64\n",
      "F33      int64\n",
      "F34      int64\n",
      "F35      int64\n",
      "Class    int64\n",
      "dtype: object\n",
      "\n",
      "Missing Values in the Training Data:\n",
      "F0       0\n",
      "F1       0\n",
      "F2       0\n",
      "F3       0\n",
      "F4       0\n",
      "F5       0\n",
      "F6       0\n",
      "F7       0\n",
      "F8       0\n",
      "F9       0\n",
      "F10      0\n",
      "F11      0\n",
      "F12      0\n",
      "F13      0\n",
      "F14      0\n",
      "F15      0\n",
      "F16      0\n",
      "F17      0\n",
      "F18      0\n",
      "F19      0\n",
      "F20      0\n",
      "F21      0\n",
      "F22      0\n",
      "F23      0\n",
      "F24      0\n",
      "F25      0\n",
      "F26      0\n",
      "F27      0\n",
      "F28      0\n",
      "F29      0\n",
      "F30      0\n",
      "F31      0\n",
      "F32      0\n",
      "F33      0\n",
      "F34      0\n",
      "F35      0\n",
      "Class    0\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in the Test Data:\n",
      "F0       0\n",
      "F1       0\n",
      "F2       0\n",
      "F3       0\n",
      "F4       0\n",
      "F5       0\n",
      "F6       0\n",
      "F7       0\n",
      "F8       0\n",
      "F9       0\n",
      "F10      0\n",
      "F11      0\n",
      "F12      0\n",
      "F13      0\n",
      "F14      0\n",
      "F15      0\n",
      "F16      0\n",
      "F17      0\n",
      "F18      0\n",
      "F19      0\n",
      "F20      0\n",
      "F21      0\n",
      "F22      0\n",
      "F23      0\n",
      "F24      0\n",
      "F25      0\n",
      "F26      0\n",
      "F27      0\n",
      "F28      0\n",
      "F29      0\n",
      "F30      0\n",
      "F31      0\n",
      "F32      0\n",
      "F33      0\n",
      "F34      0\n",
      "F35      0\n",
      "Class    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import the necessary libraries\n",
    "\n",
    "# Load the training and test data from CSV files\n",
    "train_df = pd.read_csv('data/satellite_training.csv')\n",
    "test_df = pd.read_csv('data/satellite_test.csv')\n",
    "\n",
    "# Display the data types of the columns in the training and test data\n",
    "print(\"Data Types in the Training Data:\")\n",
    "print(train_df.dtypes)\n",
    "print(\"\\nData Types in the Test Data:\")\n",
    "print(test_df.dtypes)\n",
    "\n",
    "# Check for any missing values in the training and test data\n",
    "print(\"\\nMissing Values in the Training Data:\")\n",
    "print(train_df.isnull().sum())\n",
    "print(\"\\nMissing Values in the Test Data:\")\n",
    "print(test_df.isnull().sum())\n",
    "\n",
    "# Perform feature scaling using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(train_df), columns=train_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build basic decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8565\n",
      "Precision: 0.8589412643157891\n",
      "Recall: 0.8565\n",
      "F1 Score: 0.8575488281799455\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "\n",
    "X_train = train_df.iloc[:, :-1]\n",
    "y_train = train_df.iloc[:, -1]\n",
    "X_test = test_df.iloc[:, :-1]\n",
    "y_test = test_df.iloc[:, -1]\n",
    "\n",
    "# Train the model\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('F1 Score:', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define set of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for DecisionTreeClassifier\n",
    "params = {\n",
    "    'criterion': ['gini', 'entropy'],  \n",
    "    'max_depth': [None, 5, 10, 15, 20],  \n",
    "    'min_samples_split': [2, 5, 10],  \n",
    "    'min_samples_leaf': [1, 2, 5]  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the grid search algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8275084554678692\n",
      "Best parameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(clf, params, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best result and parameters\n",
    "print('Best score:', grid_search.best_score_)\n",
    "print('Best parameters:', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the best three combinations and run each 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracies: [0.85405, 0.8513999999999999, 0.8504000000000002]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "top3_params = grid_search.cv_results_['params'][:3]\n",
    "\n",
    "# Run each 10 times\n",
    "results = []\n",
    "for params in top3_params:\n",
    "    accuracies = []\n",
    "    for _ in range(10):\n",
    "        clf = DecisionTreeClassifier(**params)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    results.append(np.mean(accuracies))\n",
    "\n",
    "# Print average accuracies\n",
    "print('Average accuracies:', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [09:56<00:00, 44308.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 65389.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:29<00:00, 147736.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 9841511.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "WRONG TENSOR SIZE\n",
      "Class names: ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import utils\n",
    "\n",
    "# Download and load the data\n",
    "transform = transforms.ToTensor()\n",
    "train_data = datasets.FashionMNIST(root='data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.FashionMNIST(root='data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Display some images\n",
    "utils.show(train_data[0][0])\n",
    "\n",
    "# Display class names\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "print('Class names:', class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x144 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(10,2))\n",
    "for i in range(5):\n",
    "    axes[i].imshow(train_data[i][0].reshape(28, 28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write two-layer FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 242762 (0.24 million) parameters in this neural network\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class FNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.softmax(self.fc4(x), dim=1)\n",
    "        return x\n",
    "\n",
    "# Create a model and display the number of parameters\n",
    "model = FNN()\n",
    "utils.display_num_param(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model and display otput probabilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output probabilities: tensor([[0.1004, 0.0913, 0.1127, 0.0946, 0.1105, 0.1177, 0.0925, 0.0910, 0.0910,\n",
      "         0.0983]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Display output probabilities for a random image\n",
    "random_image = train_data[0][0]\n",
    "output = model(random_image.unsqueeze(0))\n",
    "print('Output probabilities:', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Load the data\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "\n",
    "# Run the training\n",
    "for epoch in range(5):  # 5 epochs\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAPVUlEQVR4nO3df6zV9X3H8ddLBFR+KD8EL1SFVUTHjHYholIXl9ri/AercSl/LM6RUJO61GRmI90fNVmW6LZuif80oakpWzqbJkpKmrKWkGZu/1SRMMRiCzZQLlwhCMoPQQTe++N+WW7xfj+f6/mec7/HfZ6P5Oace973e74fzr0vvt9zPt/P5+OIEID//y5ruwEAxgdhBwpB2IFCEHagEIQdKMTl47kz23z0D/RYRHi0xxsd2W0/YPtXtvfYXtvkuQD0ljvtZ7c9QdKvJX1R0qCk1yStiohfJrbhyA70WC+O7HdK2hMRv4mIs5J+IGllg+cD0ENNwj5f0v4R3w9Wj/0O22tsb7W9tcG+ADTU5AO60U4VPnaaHhHrJK2TOI0H2tTkyD4o6foR339G0sFmzQHQK03C/pqkRbYX2p4k6SuSNnanWQC6rePT+Ig4Z/tJST+VNEHSCxHxZtdaBqCrOu5662hnvGcHeq4nF9UA+PQg7EAhCDtQCMIOFIKwA4Ug7EAhCDtQCMIOFIKwA4Ug7EAhCDtQCMIOFIKwA4Ug7EAhCDtQCMIOFIKwA4Ug7EAhCDtQCMIOFIKwA4Ug7EAhCDtQCMIOFIKwA4Ug7EAhCDtQCMIOFIKwA4Ug7EAhOl6fXZJs75V0QtJ5SeciYmk3GgWg+xqFvfLHEXGkC88DoIc4jQcK0TTsIelntl+3vWa0H7C9xvZW21sb7gtAA46Izje250XEQdtzJG2W9JcR8Uri5zvfGYAxiQiP9nijI3tEHKxuD0vaIOnOJs8HoHc6DrvtKbanXbwv6UuSdnarYQC6q8mn8XMlbbB98Xn+PSL+oyutAtB1jd6zf+Kd8Z4d6LmevGcH8OlB2IFCEHagEIQdKARhBwrRjYEwQCsmTJiQrF+4cKG21rQXavLkycn6hx9+mKzfdNNNtbU9e/Z01KYcjuxAIQg7UAjCDhSCsAOFIOxAIQg7UAjCDhSCfvbCVUOUO66n+rIlaf78+bW1u+++O7ntpk2bkvVTp04l672U60fPeeSRR2przz33XKPnrsORHSgEYQcKQdiBQhB2oBCEHSgEYQcKQdiBQtDPjqRcP3rOvffeW1tbtmxZctt58+Yl688//3xHbeqGOXPmJOsrVqxI1o8fP97N5owJR3agEIQdKARhBwpB2IFCEHagEIQdKARhBwpBP3vhcnOvnzt3LllfunRpsn7rrbfW1g4dOpTcdtGiRcn6hg0bkvWjR4/W1q688srktvv27UvWZ82alaxPnz49WR8cHEzWeyF7ZLf9gu3DtneOeGym7c22d1e3M3rbTABNjeU0/nuSHrjksbWStkTEIklbqu8B9LFs2CPiFUmXng+tlLS+ur9e0kPdbRaAbuv0PfvciBiSpIgYsl17obDtNZLWdLgfAF3S8w/oImKdpHWSZLvZanoAOtZp19sh2wOSVN0e7l6TAPRCp2HfKOmx6v5jkn7UneYA6JXsabztFyXdJ2m27UFJ35T0rKQf2l4t6beSHu1lI9G5yy5L/3+e60efMmVKsv7oo+lffWp+9SuuuCK57bRp05L13Jz2qX97btslS5Yk6/v370/Wjx07lqxffvn4X+KS3WNErKopfaHLbQHQQ1wuCxSCsAOFIOxAIQg7UAjCDhSCIa5jlOqqiUhfGJjr/sptn6unhqmeP38+uW3OE088kay/8847yfqZM2dqawsWLEhum+uayw2RTb0uuSmyc8tBnz17NlnPDXGdPHlybS3X3dnpUtUc2YFCEHagEIQdKARhBwpB2IFCEHagEIQdKEQx/ey5IY1N+7pTmi57nJvuuUlf+qpVdYMah1133XXJ+rZt25L1iRMn1tauueaa5Lbvvvtusp6aKlqSZs+eXVvLDZ/NveY5uWsrrrrqqtpabgrt7du3d9IkjuxAKQg7UAjCDhSCsAOFIOxAIQg7UAjCDhSimH72Jv3kUrrfNNenmusHz7WtST/6448/nqwvXrw4Wc9NmZzqy5bS1zfklk0+cOBAsp7rK09d3/DBBx8kt82NpW963UbKihUrknX62QEkEXagEIQdKARhBwpB2IFCEHagEIQdKMSnqp8915+dkuv3zPWbpvpsm45Xz5k3b16y/vDDD9fWcn3Zu3fvTtanTp2arKfmP5ekWbNm1dZyc6/nfmepMeE5uWsXUktNj2X73Nzuqb+Z5cuXJ7ftVDY9tl+wfdj2zhGPPWP7gO3t1deDPWkdgK4Zy6Hye5IeGOXxf4mIO6qvn3S3WQC6LRv2iHhFUnr+HwB9r8kHdE/a3lGd5s+o+yHba2xvtb21wb4ANNRp2L8t6bOS7pA0JOlbdT8YEesiYmlELO1wXwC6oKOwR8ShiDgfERckfUfSnd1tFoBu6yjstgdGfPtlSTvrfhZAf8j2s9t+UdJ9kmbbHpT0TUn32b5DUkjaK+mrY91hk7XEe9mf3WT88bXXXpus33jjjcn6LbfckqwPDAwk66n+6uPHjye3zc3dnltnPDUvvJTuh8/9PnOvW27f7733Xm3to48+Sm6ba1vumo/Tp08n66kcnDhxIrntkiVLamtvv/12bS0b9ogYbRWB7+a2A9BfuFwWKARhBwpB2IFCEHagEIQdKMS4D3FtMi3y3Llza2u5bpopU6Y0qqeGii5cuDC5bW4oZq4b6OTJk8l6qhvo6quvTm6bGwJ77ty5ZD33b0tN2ZwbRjpp0qRkfWhoKFlP/dtz7T527Fiynhv6O2NG7RXkktJDYHPLZKeGDe/bt6+2xpEdKARhBwpB2IFCEHagEIQdKARhBwpB2IFC9NVU0vfff3+ynppSOddXPWfOnGQ9N2QxNeQxt+/ckMVcn22u3zU1DXZuqudcf3Ludcm1PTWUMzfdcu51e//995P13O+8idzrlhsim7q+IXd9Qerah9RQbY7sQCEIO1AIwg4UgrADhSDsQCEIO1AIwg4UYlz72adPn6677rqrtr569erk9m+99VZtLTe2OTelcqo/WEpP15zbNifXn5zrd03NEZCbCjq3VHVuvHuuPzk13XPu+oHU/AVSekrl3L6b/s5y1wjkxsufOXOm4+c+fPhwbS3VB8+RHSgEYQcKQdiBQhB2oBCEHSgEYQcKQdiBQoxrP/upU6f06quv1tZTffCSdNttt9XWli9f3nG7pPz86Km+8KNHjya3zdVz47Jz/eypvvLUHOOStHjx4mQ911+c68dPja++/fbbk9vu2LEjWd+7d2+ynpofITfOv8kS3lL+7+nAgQO1tdw1Iak5BFLzD2SP7Lavt/1z27tsv2n769XjM21vtr27uk3Pig+gVWM5jT8n6a8i4lZJd0n6mu3fl7RW0paIWCRpS/U9gD6VDXtEDEXEtur+CUm7JM2XtFLS+urH1kt6qEdtBNAFn+g9u+0Fkj4n6ReS5kbEkDT8H4LtUSf8sr1G0prqfqPGAujcmD+Ntz1V0kuSnoqI9CcII0TEuohYGhFLc5MXAuidMaXP9kQNB/37EfFy9fAh2wNVfUBS/VAcAK1zrovBw+fe6yUdjYinRjz+j5LejYhnba+VNDMi/jrzXM36MxJyUxovW7YsWb/55puT9Xvuuae2lpuyONc9lVsuOvf2J/U7zA1BzXULpoYVS9LmzZuT9U2bNtXWUsM8u2Hjxo21tRtuuCG57ZEjR5L13LDkXD3VNZdbyvrpp5+urZ0+fVrnz58f9Q9mLO/Zl0v6M0lv2N5ePfYNSc9K+qHt1ZJ+K+nRMTwXgJZkwx4R/y2p7tDyhe42B0Cv8IkZUAjCDhSCsAOFIOxAIQg7UIhsP3tXd9bDfnYAwyJi1N4zjuxAIQg7UAjCDhSCsAOFIOxAIQg7UAjCDhSCsAOFIOxAIQg7UAjCDhSCsAOFIOxAIQg7UAjCDhSCsAOFIOxAIQg7UAjCDhSCsAOFIOxAIQg7UAjCDhQiG3bb19v+ue1dtt+0/fXq8WdsH7C9vfp6sPfNBdCp7CIRtgckDUTENtvTJL0u6SFJfyrpZET805h3xiIRQM/VLRIxlvXZhyQNVfdP2N4laX53mweg1z7Re3bbCyR9TtIvqoeetL3D9gu2Z9Rss8b2VttbmzUVQBNjXuvN9lRJ/ynp7yPiZdtzJR2RFJL+TsOn+n+ReQ5O44EeqzuNH1PYbU+U9GNJP42Ifx6lvkDSjyPiDzLPQ9iBHut4YUfblvRdSbtGBr364O6iL0va2bSRAHpnLJ/Gf17Sf0l6Q9KF6uFvSFol6Q4Nn8bvlfTV6sO81HNxZAd6rNFpfLcQdqD3WJ8dKBxhBwpB2IFCEHagEIQdKARhBwpB2IFCEHagEIQdKARhBwpB2IFCEHagEIQdKARhBwqRnXCyy45I2jfi+9nVY/2oX9vWr+2SaFunutm2G+sK4zqe/WM7t7dGxNLWGpDQr23r13ZJtK1T49U2TuOBQhB2oBBth31dy/tP6de29Wu7JNrWqXFpW6vv2QGMn7aP7ADGCWEHCtFK2G0/YPtXtvfYXttGG+rY3mv7jWoZ6lbXp6vW0Dtse+eIx2ba3mx7d3U76hp7LbWtL5bxTiwz3upr1/by5+P+nt32BEm/lvRFSYOSXpO0KiJ+Oa4NqWF7r6SlEdH6BRi2/0jSSUn/enFpLdv/IOloRDxb/Uc5IyL+pk/a9ow+4TLePWpb3TLjf64WX7tuLn/eiTaO7HdK2hMRv4mIs5J+IGllC+3oexHxiqSjlzy8UtL66v56Df+xjLuatvWFiBiKiG3V/ROSLi4z3uprl2jXuGgj7PMl7R/x/aD6a733kPQz26/bXtN2Y0Yx9+IyW9XtnJbbc6nsMt7j6ZJlxvvmtetk+fOm2gj7aEvT9FP/3/KI+ENJfyLpa9XpKsbm25I+q+E1AIckfavNxlTLjL8k6amION5mW0YapV3j8rq1EfZBSdeP+P4zkg620I5RRcTB6vawpA0aftvRTw5dXEG3uj3ccnv+T0QciojzEXFB0nfU4mtXLTP+kqTvR8TL1cOtv3ajtWu8Xrc2wv6apEW2F9qeJOkrkja20I6PsT2l+uBEtqdI+pL6bynqjZIeq+4/JulHLbbld/TLMt51y4yr5deu9eXPI2LcvyQ9qOFP5N+W9LdttKGmXb8n6X+qrzfbbpukFzV8WveRhs+IVkuaJWmLpN3V7cw+atu/aXhp7x0aDtZAS237vIbfGu6QtL36erDt1y7RrnF53bhcFigEV9ABhSDsQCEIO1AIwg4UgrADhSDsQCEIO1CI/wVqv/jzn9QWeQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned probabilities: tensor([[3.8627e-10, 1.3997e-11, 5.9276e-16, 4.5099e-10, 7.0938e-13, 2.6827e-05,\n",
      "         3.1684e-13, 1.5071e-05, 1.3196e-10, 9.9996e-01]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Display a random image from the test set and display returned probabilities\n",
    "random_image = test_data[0][0]\n",
    "plt.imshow(random_image.reshape(28, 28), cmap='gray')\n",
    "plt.show()\n",
    "output = model(random_image.unsqueeze(0))\n",
    "print('Returned probabilities:', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report the accuracy, precision, recall, and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8406\n",
      "Precision: 0.8476095124838242\n",
      "Recall: 0.8406\n",
      "F1 Score: 0.8352346356867596\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_loader = DataLoader(test_data, batch_size=len(test_data), shuffle=True)\n",
    "images, labels = next(iter(test_loader))\n",
    "output = model(images)\n",
    "_, predicted = torch.max(output, 1)\n",
    "\n",
    "# Calculate the metrics\n",
    "print('Accuracy:', accuracy_score(labels, predicted))\n",
    "print('Precision:', precision_score(labels, predicted, average='weighted'))\n",
    "print('Recall:', recall_score(labels, predicted, average='weighted'))\n",
    "print('F1 Score:', f1_score(labels, predicted, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:1345: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 93 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities: tensor([3.5075e-10, 3.8841e-05, 1.5317e-03, 9.5707e-04, 2.8229e-09, 9.0872e-09,\n",
      "        3.4520e-10, 9.9747e-01, 3.5161e-08, 1.4949e-07],\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "Accuracy: 1.0\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define the CNN model\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "      super(ConvNet, self).__init__()\n",
    "      self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "      self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "      self.dropout1 = nn.Dropout2d(0.25)\n",
    "      self.dropout2 = nn.Dropout2d(0.5)\n",
    "      self.fc1 = nn.Linear(9216, 128)\n",
    "      self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "      x = self.conv1(x)\n",
    "      x = F.relu(x)\n",
    "\n",
    "      x = self.conv2(x)\n",
    "      x = F.relu(x)\n",
    "\n",
    "      x = F.max_pool2d(x, 2)\n",
    "      x = self.dropout1(x)\n",
    "      x = torch.flatten(x, 1)\n",
    "      x = self.fc1(x)\n",
    "      x = F.relu(x)\n",
    "      x = self.dropout2(x)\n",
    "      x = self.fc2(x)\n",
    "\n",
    "      # Apply softmax to x\n",
    "      output = F.log_softmax(x, dim=1)\n",
    "      return output\n",
    "\n",
    "model = ConvNet()\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=False, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=False, transform=transforms.ToTensor())\n",
    "\n",
    "# Create the data loaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Test the model\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "# Make a single prediction\n",
    "random_index = torch.randint(len(test_dataset), size=(1,)).item()\n",
    "image, label = test_dataset[random_index]\n",
    "output = model(image.unsqueeze(0))\n",
    "probs = F.softmax(output, dim=1)\n",
    "\n",
    "# Display the image and the predicted probabilities\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image.squeeze(), cmap='gray')\n",
    "plt.show()\n",
    "print('Predicted probabilities:', probs.squeeze())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Report the accuracy, precision, recall, and the f1 score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:1345: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9371\n",
      "Precision: 0.9370055134129883\n",
      "Recall: 0.9366101321827648\n",
      "F1 score: 0.9365564805074331\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    output = model(images)\n",
    "    predicted = torch.argmax(output, dim=1)\n",
    "    \n",
    "    y_true.extend(labels.tolist())\n",
    "    y_pred.extend(predicted.tolist())\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='macro')\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 score:', f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
